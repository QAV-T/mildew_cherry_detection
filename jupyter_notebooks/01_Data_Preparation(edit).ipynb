{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "0aStgWSO0E0E",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# **Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "* Fetch data from Kaggle and save as raw data\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* Kaggle JSON file - the authentication token.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* The output of this folder is a directory named outputs/datasets/raw/csv inside in outputs which contains various CSV files. If the user wishes, they can also keep the database vrersion of the files.\n",
    "\n",
    "## Additional Comments\n",
    "\n",
    "* The dataset is image data type. It is a tabelled dataset and the class labels are healthy and powdery_mildew.\n",
    "It is a balanced dataset with each class having 2104 image data\n",
    "No non-image file was found in the dataset \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Tariq\\\\Mildew\\\\mildew_cherry_detection\\\\jupyter_notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TwHsQRWjz3i9",
    "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_xPk_Ijz3i-"
   },
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vz3S-_kjz3jA",
    "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Tariq\\\\Mildew\\\\mildew_cherry_detection'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Install Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 1 content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle==1.5.12\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "                                              0.0/59.0 kB ? eta -:--:--\n",
      "                                              0.0/59.0 kB ? eta -:--:--\n",
      "     ------                                   10.2/59.0 kB ? eta -:--:--\n",
      "     ------                                   10.2/59.0 kB ? eta -:--:--\n",
      "     -------------                           20.5/59.0 kB 93.9 kB/s eta 0:00:01\n",
      "     --------------------------             41.0/59.0 kB 196.9 kB/s eta 0:00:01\n",
      "     --------------------------             41.0/59.0 kB 196.9 kB/s eta 0:00:01\n",
      "     --------------------------------       51.2/59.0 kB 154.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 59.0/59.0 kB 173.4 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in d:\\tariq\\mildew\\mildew_cherry_detection\\mlvenv\\lib\\site-packages (from kaggle==1.5.12) (1.16.0)\n",
      "Requirement already satisfied: certifi in d:\\tariq\\mildew\\mildew_cherry_detection\\mlvenv\\lib\\site-packages (from kaggle==1.5.12) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil in d:\\tariq\\mildew\\mildew_cherry_detection\\mlvenv\\lib\\site-packages (from kaggle==1.5.12) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in d:\\tariq\\mildew\\mildew_cherry_detection\\mlvenv\\lib\\site-packages (from kaggle==1.5.12) (2.32.3)\n",
      "Collecting tqdm (from kaggle==1.5.12)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "                                              0.0/78.4 kB ? eta -:--:--\n",
      "     ---------------                          30.7/78.4 kB ? eta -:--:--\n",
      "     -----------------------------          61.4/78.4 kB 825.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 78.4/78.4 kB 732.4 kB/s eta 0:00:00\n",
      "Collecting python-slugify (from kaggle==1.5.12)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: urllib3 in d:\\tariq\\mildew\\mildew_cherry_detection\\mlvenv\\lib\\site-packages (from kaggle==1.5.12) (2.2.2)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle==1.5.12)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "                                              0.0/78.2 kB ? eta -:--:--\n",
      "     ---------------                          30.7/78.2 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------          61.4/78.2 kB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 78.2/78.2 kB 722.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\tariq\\mildew\\mildew_cherry_detection\\mlvenv\\lib\\site-packages (from requests->kaggle==1.5.12) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\tariq\\mildew\\mildew_cherry_detection\\mlvenv\\lib\\site-packages (from requests->kaggle==1.5.12) (3.7)\n",
      "Requirement already satisfied: colorama in d:\\tariq\\mildew\\mildew_cherry_detection\\mlvenv\\lib\\site-packages (from tqdm->kaggle==1.5.12) (0.4.6)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73042 sha256=1a5d8ca9100ec45a34b3f1c370c59dc4c40fa4a39d45f4067f2c2fb90d4239cf\n",
      "  Stored in directory: c:\\users\\tamam jerbi\\appdata\\local\\pip\\cache\\wheels\\70\\0c\\e6\\79103212a102e78b8453691b905f48000219574ba7137e7207\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, tqdm, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.12 python-slugify-8.0.4 text-unidecode-1.3 tqdm-4.66.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 24.2\n",
      "[notice] To update, run: D:\\Tariq\\Mildew\\mildew_cherry_detection\\mlvenv\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# install kaggle package\n",
    "%pip install kaggle==1.5.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to change the Kaggle configuration directory to the current working directory and set permissions for the Kaggle authentication JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Chmod' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "! Chmod 600 kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now download the zip file containing the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cherry-leaves.zip to inputs/datasets/raw\n",
      " 95%|███████████████████████████████████▉  | 52.0M/55.0M [00:02<00:00, 22.7MB/s]\n",
      "100%|██████████████████████████████████████| 55.0M/55.0M [00:02<00:00, 20.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"\n",
    "DestinationFolder = \"inputs/datasets/raw\"   \n",
    "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the downloaded file, and delete the zip file and the koggle tokens jason file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open inputs/datasets/raw/*.zip, inputs/datasets/raw/*.zip.zip or inputs/datasets/raw/*.zip.ZIP.\n",
      "\n",
      "No zipfiles found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! unzip {DestinationFolder}/*.zip -d {DestinationFolder} \\\n",
    "  && rm {DestinationFolder}/*.zip \\\n",
    "  && rm kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFQo3ycuO-v6"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "Check and remove non-image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: os.sep instead '/'\n",
    "#TODO: i, j should be counters not lists\n",
    "def remove_non_image_file(my_data_dir):\n",
    "    image_extension = ('.png', '.jpg', '.jpeg')\n",
    "    folders = os.listdir(my_data_dir)\n",
    "    for folder in folders:\n",
    "        files = os.listdir(my_data_dir + os.sep + folder)\n",
    "        # print(files)\n",
    "        i = []\n",
    "        j = []\n",
    "        for given_file in files:\n",
    "            if not given_file.lower().endswith(image_extension):\n",
    "                file_location = my_data_dir + os.sep + folder + os.sep + given_file\n",
    "                os.remove(file_location)  # remove non image file\n",
    "                i.append(1)\n",
    "            else:\n",
    "                j.append(1)\n",
    "                pass\n",
    "        print(f\"Folder: {folder} - has image file\", len(j))\n",
    "        print(f\"Folder: {folder} - has non-image file\", len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: healthy - has image file 2104\n",
      "Folder: healthy - has non-image file 0\n",
      "Folder: mildew - has image file 2104\n",
      "Folder: mildew - has non-image file 0\n"
     ]
    }
   ],
   "source": [
    "remove_non_image_file(my_data_dir='inputs/datasets/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\inputs\\\\datasets\\\\raw'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(\"..\",\"inputs\",\"datasets\",\"raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train, validation and test dataset\n",
    "We will split the data into 70% training, 15% validation, and 15% test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "# Define paths\n",
    "# We could use os.path.join(\"..\",\"inputs\",\"datasets\",\"raw\") instead!\n",
    "# data_dir = '../inputs/datasets/raw'\n",
    "# train_dir = '../inputs/datasets/train'\n",
    "# val_dir = '../inputs/datasets/val'\n",
    "# test_dir = '../inputs/datasets/test'\n",
    "data_dir = os.path.join(\".\",\"inputs\",\"datasets\",\"raw\")\n",
    "train_dir = os.path.join(\".\",\"inputs\",\"datasets\",\"train\")\n",
    "val_dir = os.path.join(\".\",\"inputs\",\"datasets\",\"val\")\n",
    "test_dir = os.path.join(\".\",\"inputs\",\"datasets\",\"test\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for dir_path in [train_dir, val_dir, test_dir]:\n",
    "    for class_dir in ['healthy', 'mildew']:\n",
    "        os.makedirs(os.path.join(dir_path, class_dir), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(os.path.join(\".\",\"inputs\",\"datasets\",\"raw\",\"healthy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Helper function to split data\n",
    "def split_data(source_dir, train_dir, val_dir, test_dir, test_size=0.15, val_size=0.15):\n",
    "    all_files = [os.path.join(source_dir, f) for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
    "    train_files, test_files = train_test_split(all_files, test_size=test_size, random_state=42)\n",
    "    train_files, val_files = train_test_split(train_files, test_size=val_size/(1-test_size), random_state=42)\n",
    "\n",
    "    # Copy files to their respective directories\n",
    "    for file in train_files:\n",
    "        shutil.copy(file, os.path.join(train_dir, os.path.basename(file)))\n",
    "    for file in val_files:\n",
    "        shutil.copy(file, os.path.join(val_dir, os.path.basename(file)))\n",
    "    for file in test_files:\n",
    "        shutil.copy(file, os.path.join(test_dir, os.path.basename(file)))\n",
    "\n",
    "# Split healthy leaves\n",
    "split_data(os.path.join(data_dir, 'healthy'), os.path.join(train_dir, 'healthy'), os.path.join(val_dir, 'healthy'), os.path.join(test_dir, 'healthy'))\n",
    "\n",
    "# Split mildew leaves\n",
    "split_data(os.path.join(data_dir, 'mildew'), os.path.join(train_dir, 'mildew'), os.path.join(val_dir, 'mildew'), os.path.join(test_dir, 'mildew'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../inputs/datasets/raw\\\\healthy'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data_dir\n",
    "os.path.join(data_dir, r\"healthy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\inputs\\\\datasets\\\\raw\\\\healthy'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.normpath(os.path.join(data_dir, r\"healthy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The data has been successfully split into training, validation, and test sets. We now have separate directories for each set and class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Next, we'll move on to data visualization. This involves:\n",
    "\n",
    "   - Visualizing the average and variability of images per label to identify any patterns or inconsistencies.\n",
    "   - Comparing average images of different labels to understand the visual differences.\n",
    "   - Creating image montages to get a visual overview of the dataset, enhancing our understanding of the data's diversity and characteristics."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
